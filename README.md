## API Глоссарь терминов ВКР на C# .NET 10

---

Через docker-compose не разворачивается, потому что приложения web api и grpc используют в некоторых местах файлы с
одинаковыми названиями и из-за этого происходят конфликты при деплое в докере. Но ничего страшного, можно эти два
приложения запустить по отдельности <i>(из директории где расположен `.sln` файл)</i>:

`docker network create app-network`

```
docker build -t diplomadictionary-webapi -f ./DiplomaDictionary/Dockerfile .
docker build -t diplomadictionary-grpc -f ./GrpcService/Dockerfile .
```

`docker run -d --name webapi --network app-network -p 5000:8080 -v "./\data:/data" -e ASPNETCORE_ENVIRONMENT=Development -e ConnectionStrings__DefaultConnection="Data Source=/data/dictionary.db" diplomadictionary-webapi`

`docker run -d --name grpc --network app-network -p 5001:8080 -v "./\data:/data" -e ASPNETCORE_ENVIRONMENT=Development -e ConnectionStrings__DefaultConnection="Data Source=/data/dictionary.db" diplomadictionary-grpc`

### Структура БД

---

В базе данных SQLite есть две таблицы:

- `Term` с полями `Id`, `Name`, `Definition`, `SubjectId` - термин: название, определение и предметная область, к
  которой он относится
- `Subject` с полями `Id` и `Name` - предметная область

Например, есть термин , и этот термин "Веб-сервер" с определением "компьтерная программа, которая находится в состоянии
непрерывного выполнения и обработки входящих подключений за счёт...", который относится к предметной области "
Веб-программирование"

### 1) WEB API

---

Приложение работает на dotnet 10, структура выглядит следущим образом:

а) Проект `./DiplomaDictionary/` - точка входа в приложение:

- `Program.cs` - точка входа в приложение - конфигурация методов расширения: благодаря ним можно вынести, например,
  настройку подключения к бд и миграции в отдельные файлы (`Extensions/DbContextExtenstions.cs` и
  `Extensitons/MigrationExtensions.cs`) отедльные файлы и вызвать в `Program.cs`, также настройка Swagger и DI
- `Controllers/ComceptController.cs` - HTTP эндпоинты приложения, бизнес логика описана в Domain проекте

б) Проект `DiplomaDictionary.Domain` - слой бизнес логики, для такого простого приложения достаточно описать только
`./Services` директорию, и с `ConceptService.cs` будут работать эндпоинты, независимо, это web api реализация, grpc, или
любая другая

в) Проект `DiplomaDictionary.Data` - слой данных: описаны DTO; ORM модели; миграционные скрипты, генерируемые
`EntityFramework Core` - самым распространённым ORM фреймворком для C#; также реализация класса `DbContext` через
конкретный `ApplicationDbContext`, благодаря которому можно пользоваться всем функционалом `EntityFramework Core` и
обёртка в виде паттерна `IUnitOfWork`.

г) k6-testing - проект с нагрузочными тестами с помощью js библиотеки k6, <i>об этом в параграфе 3</i>

д) GrpcService - проект с реализацией grpc - об этом далее

---

### 2) Grpc

в этом проекте все просто:

- `Protos/concept.proto` - protobuff файл, с описанием всех интерфейсов для программы
- `Services/ConceptGrpcService.cs` - реализация grpc сервиса, где по сути вызываются методы Domain проекта
- `Program.cs` - точка входа, аналогична точке входа из web api проекта

---

также стоит отметить особенность разработки grpc приложения на dotnet, прежде чем начать писать grpc сервисы, необходимо
написать методы в .proto файле, затем собрать проетк `dotnet build ./GrpcService.csproj` сишарп сгенерирует в директорию
build классы, которые переопределяются с помощью `override` программистом и уже затем работают как эндпоинты.

---

### 3) Нагрузочное тестирование

Несмотря на то, что в задании было указано проводить тестирование с помощью Locust, мною было принято решение провести
тесты с помощью k6. Это обосновано большей лаконичностью и удобством проведения тестов, т.к. k6 работает только в режиме
CLI, и не имеет пользовательского интерфейса. Поэтому k6 подходит для запуска тестов в CI/CD пайплайне и предоставляет
удобство написания тестов с помощью javascript.

В директориях `webapi/` и `grpc/` находятся одинаковые тесты, для web api и grpc:

- `smoke.js` - слабый тест с минимальной нагрузкой
- `average-load.js` - тест имитирующий среднюю нагрузку с плавным нарастанием и затуханием
- `stress.js` - тест имитирующий большую нагрузку с плавным нарастанием и затуханием
- `spike.js` - тест имитирующий большую нагрузку с резким нарастанием и затуханием

также было проведено сидирование БД ничем не значащими данными в `random-seeding.js`

тесты можно запустить с помощью команды `k6 run smoke.js` или любой другой файл, и также нужно иметь установаленный k6,
для windows подойдет `choco install k6`.

Аппаратные характеристики компьютера, на котором тестировались приложения:

- Intel Core i5-7500 3.4Hz
- 16 GB RAM
- 4 GB GPU

<i>(да, решил запустить не в докере а локально, Windows 10, на dotnet сервере kestrel)</i>

---

Тестировался эндпоинт GetAllTerms, который возвращает все клонки таблицы `Terms` вместе со связанными `Subject` по
`inner join`. Результаты тестов генерировались в виде .html страниц в директории `results/` в директориях `webapi/` и
`grpc/`
соответственно. У grpc получается тестировался unary request/response, а не стриминг. По результатам бенчмарка я сделал
следующие выводы:

1) <b>smoke</b>: никакой разницы между web api и grpc. у grpc чуть меньше `data sent`, но у web api чуть меньше
   `data received`
2) <b>averag-load</b>: у web api `req_duration` в два раза меньше чем у grpc, но здесь наоборот - `data sent` у web api
   меньше, а `data received` у web api больше
3) <b>stress</b>: здесь grpc показал себя лучше - `req_duration` в два раза меньше, но и `data sent` значительно больше
4) <b>spike</b>: здесь web api показал себя лучше по всем параметрам (описательным статистикам), `data sent` почему-то у
   grpc больше.

Из узких мест можно выделить значительный объём ОЗУ, потребляемый обоими приложениями; и нагрузку на сборщик
мусора (что указывает на то, что я не озаботился оптимизацией кода). Также огромный объём трафика, например для Spike
объём составил 2ГБ полученных данных, но это потому что я возвращал html страницу со всеми записями.

---

Улучшить эксперимент можно:

- более правдоподобными на пользовательское поведение сценариями тестов;
- тестированием других эндпоинтов (с оптимизированным кодом);
- стриминг grpc;
- протестировать в docker, где наложить ограничения на ресурсы.